"""
ì˜¨í†¨ë¡œì§€ êµ¬ì¶• ëª¨ë“ˆ
í•˜ì´ë¸Œë¦¬ë“œ ë§¤í•‘ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ RDF ì˜¨í†¨ë¡œì§€ êµ¬ì¶•
"""

import os
import urllib.parse
import pandas as pd
from rdflib import Graph, Literal, RDF, Namespace, XSD
from typing import List

from backend.services.ontology_services.config import BASE_URI, FACT_URI, DEFAULT_MODEL
from backend.services.ontology_services.hybrid_mapper import HybridMapper
from backend.services.ontology_services.config import INPUT_DATA_FOLDER, OUTPUT_DATA_FOLDER, OUTPUT_FILE


def build_hybrid_ontology(
    ontology_classes: List[str],
    model_name: str = DEFAULT_MODEL
):
    """
    í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ë²•ìœ¼ë¡œ ì˜¨í†¨ë¡œì§€ êµ¬ì¶• (íŒŒì¼ëª…ë§Œ ì‚¬ìš©)
    
    Args:
        input_folder: CSV íŒŒì¼ì´ ìˆëŠ” í´ë”
        ontology_classes: í‘œì¤€ ì˜¨í†¨ë¡œì§€ í´ë˜ìŠ¤ ë¦¬ìŠ¤íŠ¸
        output_file: ì¶œë ¥ TTL íŒŒì¼ëª…
        model_name: SentenceTransformer ëª¨ë¸ëª…
    
    Returns:
        tuple: (ë§¤í•‘ ê²°ê³¼ DataFrame, RDF Graph)
    """
    print("í•˜ì´ë¸Œë¦¬ë“œ ì˜¨í†¨ë¡œì§€ êµ¬ì¶•ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì„¤ì •
    META = Namespace(BASE_URI)
    FACT = Namespace(FACT_URI)
    g = Graph()
    g.bind("meta", META)
    g.bind("fact", FACT)
    
    # í•˜ì´ë¸Œë¦¬ë“œ ë§¤í¼ ì´ˆê¸°í™”
    mapper = HybridMapper(ontology_classes, model_name)
    
    # í´ë” ë‚´ íŒŒì¼ íƒìƒ‰
    if not os.path.exists(INPUT_DATA_FOLDER):
        os.makedirs(INPUT_DATA_FOLDER)
        print(f"   [ì•ˆë‚´] '{INPUT_DATA_FOLDER}' í´ë”ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        # ë¹ˆ DataFrameê³¼ Graph ë°˜í™˜
        return pd.DataFrame(), g
    
    files = [f for f in os.listdir(INPUT_DATA_FOLDER) if f.endswith((".csv", ".CSV"))]
    
    if not files:
        print(f"   [ê²½ê³ ] '{INPUT_DATA_FOLDER}' í´ë”ì— CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        # ë¹ˆ DataFrameê³¼ Graph ë°˜í™˜
        return pd.DataFrame(), g
    
    # í•˜ì´ë¸Œë¦¬ë“œ ë§¤í•‘ ìˆ˜í–‰ (íŒŒì¼ëª…ë§Œ ì‚¬ìš©)
    mapping_df = mapper.map_files(files)
    
    print("\nğŸ“Š ë§¤í•‘ ê²°ê³¼:")
    print(mapping_df.to_string(index=False))
    
    # ì˜¨í†¨ë¡œì§€ êµ¬ì¶• (íŒŒì¼ëª…ê³¼ ì˜¨í†¨ë¡œì§€ í´ë˜ìŠ¤ë§Œ ë§¤í•‘)
    for _, row in mapping_df.iterrows():
        filename = row['Filename']
        mapped_class = row['Mapped_Class']
        confidence = row['Confidence']
        method = row['Method']
        
        if mapped_class == "Unclassified":
            print(f"   âš ï¸  {filename}: ë§¤í•‘ ì‹¤íŒ¨ (ìˆ˜ë™ ê²€í†  í•„ìš”)")
            continue
        
        # URI ìƒì„±
        dataset_name = os.path.splitext(filename)[0]
        dataset_uri = FACT[urllib.parse.quote(dataset_name)]
        class_uri = FACT[urllib.parse.quote(mapped_class)]
        
        # ë°ì´í„°ì…‹ ê°ì²´ ìƒì„± (íŒŒì¼ëª…ê³¼ ì˜¨í†¨ë¡œì§€ í´ë˜ìŠ¤ë§Œ)
        # g.add((dataset_uri, RDF.type, META.Dataset))
        # g.add((dataset_uri, META.hasFileName, Literal(filename)))
        
        # í´ë˜ìŠ¤ ë§¤í•‘
        g.add((dataset_uri, FACT.isDataOf, class_uri))
        
        print(f"   âœ… {filename} â†’ {mapped_class} ({method}, confidence: {confidence:.2f})")
    
    # ê²°ê³¼ ì €ì¥
    if len(mapping_df) > 0:  # íŒŒì¼ì´ ìˆì„ ë•Œë§Œ ì €ì¥
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„± (ì—†ìœ¼ë©´)
        if not os.path.exists(OUTPUT_DATA_FOLDER):
            os.makedirs(OUTPUT_DATA_FOLDER, exist_ok=True)
            print(f"   [ì•ˆë‚´] '{OUTPUT_DATA_FOLDER}' í´ë”ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        output_path = os.path.join(OUTPUT_DATA_FOLDER, OUTPUT_FILE)
        g.serialize(destination=output_path, format="turtle")
        print(f"\nâœ… ì˜¨í†¨ë¡œì§€ êµ¬ì¶• ì™„ë£Œ! ({output_path})")
        
        # í†µê³„ ì¶œë ¥
        method_counts = mapping_df['Method'].value_counts()
        print("\nğŸ“ˆ ë§¤í•‘ ë°©ë²• í†µê³„:")
        for method, count in method_counts.items():
            print(f"   {method}: {count}ê°œ")
    
    return mapping_df, g

