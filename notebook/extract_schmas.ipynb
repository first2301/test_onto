{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5978311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3559276",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "df = pl.read_csv(\"./csv_data//deoksan.csv\")\n",
    "col_lis = list(df.schema.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9da1c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = df.unpivot(\n",
    "    index=[\"time\"], \n",
    "    variable_name=\"sensor_key\", \n",
    "    value_name=\"sensor_value\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0061d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54181864"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(long_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dac27e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "['time', 'curr', 'currR', 'currS', 'currT', 'Ground', 'PT100', 'Vibra', 'Volt', 'VoltR', 'VoltS', 'VoltT']\n"
     ]
    }
   ],
   "source": [
    "print(len(col_lis))\n",
    "print(col_lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91118cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lis = [\"time\", \"curr\", \"open\", \"high\", \"low\", \"close\", \"volume\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083ceed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_col = model.encode(col_lis)\n",
    "embeddings_test = model.encode(test_lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d59706",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim = util.pytorch_cos_sim(embeddings_col, embeddings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8603cdc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.2815, 0.3500, 0.3599, 0.2940, 0.3690, 0.2843],\n",
       "        [0.2815, 1.0000, 0.2494, 0.2326, 0.1609, 0.2941, 0.1359],\n",
       "        [0.2526, 0.8962, 0.2469, 0.1903, 0.1107, 0.2960, 0.1507],\n",
       "        [0.2837, 0.7859, 0.2376, 0.1964, 0.1306, 0.2623, 0.1399],\n",
       "        [0.3048, 0.8718, 0.2288, 0.1948, 0.1153, 0.3028, 0.1356],\n",
       "        [0.2937, 0.1676, 0.2247, 0.3562, 0.3964, 0.2598, 0.2770],\n",
       "        [0.2539, 0.1860, 0.1843, 0.2260, 0.2490, 0.2050, 0.2276],\n",
       "        [0.1850, 0.2069, 0.2003, 0.1871, 0.1757, 0.2397, 0.1827],\n",
       "        [0.3318, 0.2287, 0.2352, 0.3520, 0.3484, 0.3218, 0.5543],\n",
       "        [0.2524, 0.2876, 0.2477, 0.3130, 0.2403, 0.2996, 0.4205],\n",
       "        [0.3014, 0.2136, 0.2043, 0.3438, 0.3655, 0.2958, 0.5674],\n",
       "        [0.2648, 0.2697, 0.2373, 0.3036, 0.2599, 0.3133, 0.3714]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbba852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_sim = pd.DataFrame(\n",
    "    cos_sim.numpy(),\n",
    "    index=col_lis,\n",
    "    columns=test_lis\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79538e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>curr</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.281514</td>\n",
       "      <td>0.349970</td>\n",
       "      <td>0.359886</td>\n",
       "      <td>0.294038</td>\n",
       "      <td>0.369033</td>\n",
       "      <td>0.284349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curr</th>\n",
       "      <td>0.281514</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.249423</td>\n",
       "      <td>0.232571</td>\n",
       "      <td>0.160885</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.135923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currR</th>\n",
       "      <td>0.252592</td>\n",
       "      <td>0.896221</td>\n",
       "      <td>0.246941</td>\n",
       "      <td>0.190300</td>\n",
       "      <td>0.110683</td>\n",
       "      <td>0.296023</td>\n",
       "      <td>0.150738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currS</th>\n",
       "      <td>0.283679</td>\n",
       "      <td>0.785856</td>\n",
       "      <td>0.237553</td>\n",
       "      <td>0.196365</td>\n",
       "      <td>0.130628</td>\n",
       "      <td>0.262291</td>\n",
       "      <td>0.139895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currT</th>\n",
       "      <td>0.304782</td>\n",
       "      <td>0.871761</td>\n",
       "      <td>0.228802</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>0.115335</td>\n",
       "      <td>0.302783</td>\n",
       "      <td>0.135615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ground</th>\n",
       "      <td>0.293742</td>\n",
       "      <td>0.167581</td>\n",
       "      <td>0.224695</td>\n",
       "      <td>0.356201</td>\n",
       "      <td>0.396437</td>\n",
       "      <td>0.259835</td>\n",
       "      <td>0.276982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT100</th>\n",
       "      <td>0.253947</td>\n",
       "      <td>0.186023</td>\n",
       "      <td>0.184275</td>\n",
       "      <td>0.226033</td>\n",
       "      <td>0.248988</td>\n",
       "      <td>0.204997</td>\n",
       "      <td>0.227554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vibra</th>\n",
       "      <td>0.185005</td>\n",
       "      <td>0.206896</td>\n",
       "      <td>0.200322</td>\n",
       "      <td>0.187099</td>\n",
       "      <td>0.175703</td>\n",
       "      <td>0.239717</td>\n",
       "      <td>0.182725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volt</th>\n",
       "      <td>0.331780</td>\n",
       "      <td>0.228741</td>\n",
       "      <td>0.235239</td>\n",
       "      <td>0.351962</td>\n",
       "      <td>0.348422</td>\n",
       "      <td>0.321800</td>\n",
       "      <td>0.554284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VoltR</th>\n",
       "      <td>0.252428</td>\n",
       "      <td>0.287573</td>\n",
       "      <td>0.247696</td>\n",
       "      <td>0.313022</td>\n",
       "      <td>0.240265</td>\n",
       "      <td>0.299600</td>\n",
       "      <td>0.420484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VoltS</th>\n",
       "      <td>0.301381</td>\n",
       "      <td>0.213611</td>\n",
       "      <td>0.204318</td>\n",
       "      <td>0.343850</td>\n",
       "      <td>0.365549</td>\n",
       "      <td>0.295823</td>\n",
       "      <td>0.567370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VoltT</th>\n",
       "      <td>0.264786</td>\n",
       "      <td>0.269703</td>\n",
       "      <td>0.237285</td>\n",
       "      <td>0.303561</td>\n",
       "      <td>0.259940</td>\n",
       "      <td>0.313299</td>\n",
       "      <td>0.371440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            time      curr      open      high       low     close    volume\n",
       "time    1.000000  0.281514  0.349970  0.359886  0.294038  0.369033  0.284349\n",
       "curr    0.281514  1.000000  0.249423  0.232571  0.160885  0.294118  0.135923\n",
       "currR   0.252592  0.896221  0.246941  0.190300  0.110683  0.296023  0.150738\n",
       "currS   0.283679  0.785856  0.237553  0.196365  0.130628  0.262291  0.139895\n",
       "currT   0.304782  0.871761  0.228802  0.194801  0.115335  0.302783  0.135615\n",
       "Ground  0.293742  0.167581  0.224695  0.356201  0.396437  0.259835  0.276982\n",
       "PT100   0.253947  0.186023  0.184275  0.226033  0.248988  0.204997  0.227554\n",
       "Vibra   0.185005  0.206896  0.200322  0.187099  0.175703  0.239717  0.182725\n",
       "Volt    0.331780  0.228741  0.235239  0.351962  0.348422  0.321800  0.554284\n",
       "VoltR   0.252428  0.287573  0.247696  0.313022  0.240265  0.299600  0.420484\n",
       "VoltS   0.301381  0.213611  0.204318  0.343850  0.365549  0.295823  0.567370\n",
       "VoltT   0.264786  0.269703  0.237285  0.303561  0.259940  0.313299  0.371440"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb977389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw_Column</th>\n",
       "      <th>Mapped_Ontology</th>\n",
       "      <th>Score</th>\n",
       "      <th>Assessment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>time</td>\n",
       "      <td>time</td>\n",
       "      <td>1.00</td>\n",
       "      <td>‚úÖ Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>curr</td>\n",
       "      <td>curr</td>\n",
       "      <td>1.00</td>\n",
       "      <td>‚úÖ Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>currR</td>\n",
       "      <td>curr</td>\n",
       "      <td>0.90</td>\n",
       "      <td>‚úÖ Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>currS</td>\n",
       "      <td>curr</td>\n",
       "      <td>0.79</td>\n",
       "      <td>‚úÖ Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>currT</td>\n",
       "      <td>curr</td>\n",
       "      <td>0.87</td>\n",
       "      <td>‚úÖ Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ground</td>\n",
       "      <td>low</td>\n",
       "      <td>0.40</td>\n",
       "      <td>‚ö†Ô∏è Check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PT100</td>\n",
       "      <td>time</td>\n",
       "      <td>0.25</td>\n",
       "      <td>‚ö†Ô∏è Check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vibra</td>\n",
       "      <td>close</td>\n",
       "      <td>0.24</td>\n",
       "      <td>‚ö†Ô∏è Check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Volt</td>\n",
       "      <td>volume</td>\n",
       "      <td>0.55</td>\n",
       "      <td>‚úÖ Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VoltR</td>\n",
       "      <td>volume</td>\n",
       "      <td>0.42</td>\n",
       "      <td>‚ö†Ô∏è Check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VoltS</td>\n",
       "      <td>volume</td>\n",
       "      <td>0.57</td>\n",
       "      <td>‚úÖ Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>VoltT</td>\n",
       "      <td>volume</td>\n",
       "      <td>0.37</td>\n",
       "      <td>‚ö†Ô∏è Check</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Raw_Column Mapped_Ontology  Score Assessment\n",
       "0        time            time   1.00     ‚úÖ Good\n",
       "1        curr            curr   1.00     ‚úÖ Good\n",
       "2       currR            curr   0.90     ‚úÖ Good\n",
       "3       currS            curr   0.79     ‚úÖ Good\n",
       "4       currT            curr   0.87     ‚úÖ Good\n",
       "5      Ground             low   0.40   ‚ö†Ô∏è Check\n",
       "6       PT100            time   0.25   ‚ö†Ô∏è Check\n",
       "7       Vibra           close   0.24   ‚ö†Ô∏è Check\n",
       "8        Volt          volume   0.55     ‚úÖ Good\n",
       "9       VoltR          volume   0.42   ‚ö†Ô∏è Check\n",
       "10      VoltS          volume   0.57     ‚úÖ Good\n",
       "11      VoltT          volume   0.37   ‚ö†Ô∏è Check"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for i, src in enumerate(col_lis):\n",
    "    best_idx = cos_sim[i].argmax().item()\n",
    "    best_score = cos_sim[i][best_idx].item()\n",
    "    best_target = test_lis[best_idx]\n",
    "    \n",
    "    results.append({\n",
    "        \"Raw_Column\": src,\n",
    "        \"Mapped_Ontology\": best_target,\n",
    "        \"Score\": round(best_score, 2),\n",
    "        \"Assessment\": \"‚úÖ Good\" if best_score > 0.5 else \"‚ö†Ô∏è Check\" # ÏûÑÍ≥ÑÍ∞íÏùÄ ÏÉÅÌô©Îî∞Îùº Ï°∞Ï†à\n",
    "    })\n",
    "\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5546a76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ïª¨ÎüºÎ™ÖÎßå Ï∂îÏ∂úÌï¥ÏÑú ÏûÑÎ≤†Îî© ÌõÑ shapeÏôÄ ÏùºÎ∂Ä Í∞íÎßå Ï∂úÎ†•ÌïòÎèÑÎ°ù Í∞úÏÑ†\n",
    "column_names = [col for col, dtype in df.schema.items()]\n",
    "embeddings = model.encode(column_names)\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n",
    "print(\"First vector:\", embeddings[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e671df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ÏóâÎßùÏù∏ ÌååÏùºÎ™Ö Î¶¨Ïä§Ìä∏ (Input Data)\n",
    "filenames = [\n",
    "    \"Inj_Machine_Log_01.csv\",       # ÏïΩÏñ¥ ÏÇ¨Ïö©\n",
    "    \"Plastic_Molding_Data.csv\",     # ÎèôÏùòÏñ¥ ÏÇ¨Ïö©\n",
    "    \"Robot_Arm_Axis_X.csv\",         # Íµ¨Ï≤¥Ï†Å Î∂ÄÌíà\n",
    "    \"Auto_Welder_Final.csv\",        # Ïö©Ï†ëÍ∏∞\n",
    "    \"Factory_Pump_Vib.csv\",         # ÌéåÌîÑ\n",
    "    \"M01_Unknown.csv\",               # ÏùòÎØ∏ Î∂àÎ™Ö (Îß§Ìïë Ïã§Ìå® ÏòàÏÉÅ)\n",
    "    \"CNC_Machine_Data.csv\",\n",
    "    \"cnc.csv\",\n",
    "    \"cnc_data.csv\",\n",
    "    \"cnc_data_01.csv\",\n",
    "    \"cnc_data_02.csv\",\n",
    "    \"cnc_data_03.csv\",\n",
    "    \"cnc_data_04.csv\",\n",
    "    \n",
    "]\n",
    "\n",
    "# 3. Ïò®ÌÜ®Î°úÏßÄ ÌëúÏ§Ä ÌÅ¥ÎûòÏä§ Ï†ïÏùò (Target Classes)\n",
    "# AIÍ∞Ä ÌååÏùºÎ™ÖÏùÑ Î≥¥Í≥† Ïù¥ Ï§ë ÌïòÎÇòÎ•º Í≥®ÎùºÏïº Ìï®\n",
    "ontology_classes = [\n",
    "    \"Injection_Molding_Machine\", # ÏÇ¨Ï∂úÍ∏∞\n",
    "    \"Welding_Robot\",             # Ïö©Ï†ë Î°úÎ¥á\n",
    "    \"Industrial_Pump\",           # ÌéåÌîÑ\n",
    "    \"CNC_Machine\",               # CNC\n",
    "    \"Conveyor_Belt\"              # Ïª®Î≤†Ïù¥Ïñ¥\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5314b584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_filename(fname):\n",
    "    # ÌôïÏû•Ïûê Ï†úÍ±∞ Î∞è ÌäπÏàòÎ¨∏ÏûêÎ•º Í≥µÎ∞±ÏúºÎ°ú Î≥ÄÌôòÌïòÏó¨ 'Î¨∏Ïû•'Ï≤òÎüº ÎßåÎì¶\n",
    "    name = fname.replace('.csv', '').replace('_', ' ').replace('-', ' ')\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3ae2067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def map_filenames_to_classes(files, classes):\n",
    "    # ÏûÑÎ≤†Îî©\n",
    "    clean_names = [preprocess_filename(f) for f in files]\n",
    "    embeddings_files = model.encode(clean_names)\n",
    "    embeddings_classes = model.encode(classes)\n",
    "    \n",
    "    # Ïú†ÏÇ¨ÎèÑ Í≥ÑÏÇ∞\n",
    "    scores = util.cos_sim(embeddings_files, embeddings_classes)\n",
    "    \n",
    "    results = []\n",
    "    for i, fname in enumerate(files):\n",
    "        best_idx = scores[i].argmax().item()\n",
    "        best_score = scores[i][best_idx].item()\n",
    "        best_class = classes[best_idx]\n",
    "        \n",
    "        # Ïú†ÏÇ¨ÎèÑÍ∞Ä ÎÇÆÏúºÎ©¥(0.4 ÎØ∏Îßå) Î∂ÑÎ•ò Î≥¥Î•ò\n",
    "        category = best_class if best_score > 0.4 else \"Unclassified\"\n",
    "        \n",
    "        results.append({\n",
    "            \"Filename\": fname,\n",
    "            \"Interpreted_As\": clean_names[i],\n",
    "            \"Mapped_Class\": category,\n",
    "            \"Confidence\": round(best_score, 3)\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef5ada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "from rdflib import Graph, Literal, RDF, Namespace, XSD\n",
    "import urllib.parse\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. ÏÑ§Ï†ï\n",
    "INPUT_FOLDER = \"./factory_data\"  # Îç∞Ïù¥ÌÑ∞Í∞Ä Ï†ÄÏû•Îêú Ìè¥Îçî\n",
    "META_FILE = \"metadata_ontology.ttl\"\n",
    "\n",
    "# ÎÑ§ÏûÑÏä§ÌéòÏù¥Ïä§ ÏÑ§Ï†ï\n",
    "BASE_URI = \"http://factory.org/meta/\"\n",
    "META = Namespace(BASE_URI)\n",
    "g = Graph()\n",
    "g.bind(\"meta\", META)\n",
    "\n",
    "def build_metadata_dataset():\n",
    "    print(\"üßê Î©îÌÉÄ Îç∞Ïù¥ÌÑ∞ÏÖã Íµ¨Ï∂ïÏùÑ ÏãúÏûëÌï©ÎãàÎã§...\")\n",
    "    \n",
    "    # Ìè¥Îçî ÎÇ¥ ÌååÏùº ÌÉêÏÉâ\n",
    "    if not os.path.exists(INPUT_FOLDER):\n",
    "        os.makedirs(INPUT_FOLDER)\n",
    "        print(f\"   [ÏïàÎÇ¥] '{INPUT_FOLDER}' Ìè¥ÎçîÍ∞Ä ÏÉùÏÑ±ÎêòÏóàÏäµÎãàÎã§. Îç∞Ïù¥ÌÑ∞Î•º ÎÑ£Í≥† Îã§Ïãú Ïã§ÌñâÌï¥ Ï£ºÏÑ∏Ïöî.\")\n",
    "        return\n",
    "\n",
    "    files = [f for f in os.listdir(INPUT_FOLDER) if f.endswith(\".csv\")]\n",
    "    \n",
    "    for filename in files:\n",
    "        file_path = os.path.join(INPUT_FOLDER, filename)\n",
    "        \n",
    "        # 1. [ÌïµÏã¨] Polars Lazy APIÎ°ú Ïä§ÌÇ§ÎßàÎßå Îπ†Î•¥Í≤å Ïä§Ï∫î (Îç∞Ïù¥ÌÑ∞ Î°úÎî© X)\n",
    "        try:\n",
    "            # scan_csvÎäî Ïã§Ï†ú Îç∞Ïù¥ÌÑ∞Î•º Î©îÎ™®Î¶¨Ïóê Ïò¨Î¶¨ÏßÄ ÏïäÏäµÎãàÎã§. Îß§Ïö∞ Îπ†Î¶ÖÎãàÎã§.\n",
    "            lf = pl.scan_csv(file_path)\n",
    "            schema = lf.collect_schema() # Ïª¨Îüº Ï†ïÎ≥¥Îßå Í∞ÄÏ†∏Ïò¥\n",
    "        except Exception as e:\n",
    "            print(f\"   [Ï£ºÏùò] ÌååÏùºÏùÑ ÏùΩÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {filename} ({e})\")\n",
    "            continue\n",
    "\n",
    "        # 2. Îç∞Ïù¥ÌÑ∞ÏÖã(ÌååÏùº) Í∞ùÏ≤¥ ÏÉùÏÑ±\n",
    "        # ÌååÏùºÎ™ÖÏùÑ IDÎ°ú ÏÇ¨Ïö©\n",
    "        dataset_name = os.path.splitext(filename)[0]\n",
    "        dataset_uri = META[urllib.parse.quote(dataset_name)]\n",
    "        \n",
    "        g.add((dataset_uri, RDF.type, META.Dataset))\n",
    "        g.add((dataset_uri, META.hasFilePath, Literal(os.path.abspath(file_path)))) # Î¨ºÎ¶¨Ï†Å Í≤ΩÎ°ú Ï†ÄÏû•\n",
    "        g.add((dataset_uri, META.hasFileName, Literal(filename)))\n",
    "        \n",
    "        # 3. Ïª¨Îüº Ï†ïÎ≥¥(Î©îÌÉÄÎç∞Ïù¥ÌÑ∞) Îì±Î°ù\n",
    "        print(f\"   Process: {filename} (Ïª¨Îüº {len(schema)}Í∞ú Î∞úÍ≤¨)\")\n",
    "        \n",
    "        for col_name, data_type in schema.items():\n",
    "            # Ïª¨Îüº Í∞ùÏ≤¥ ÏÉùÏÑ± (Dataset_ColumnName)\n",
    "            col_id = f\"{dataset_name}_{col_name}\"\n",
    "            col_uri = META[urllib.parse.quote(col_id)]\n",
    "            \n",
    "            # Í¥ÄÍ≥Ñ ÏÑ§Ï†ï: Îç∞Ïù¥ÌÑ∞ÏÖã --[hasColumn]--> Ïª¨Îüº\n",
    "            g.add((col_uri, RDF.type, META.DataColumn))\n",
    "            g.add((dataset_uri, META.hasColumn, col_uri))\n",
    "            \n",
    "            # Ïª¨Îüº ÏÜçÏÑ± Ï†ÄÏû• (Ïù¥Î¶Ñ, Îç∞Ïù¥ÌÑ∞ ÌÉÄÏûÖ)\n",
    "            g.add((col_uri, META.columnName, Literal(col_name)))\n",
    "            g.add((col_uri, META.dataType, Literal(str(data_type))))\n",
    "\n",
    "    # Í≤∞Í≥º Ï†ÄÏû•\n",
    "    g.serialize(destination=META_FILE, format=\"turtle\")\n",
    "    print(f\"‚úÖ Î©îÌÉÄ Îç∞Ïù¥ÌÑ∞ÏÖã Íµ¨Ï∂ïÏù¥ ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§! ({META_FILE})\")\n",
    "\n",
    "# Ïã§Ìñâ\n",
    "if __name__ == \"__main__\":\n",
    "    # ÌÖåÏä§Ìä∏Ïö© ÎçîÎØ∏ ÌååÏùº ÏÉùÏÑ± (ÏóÜÏùÑ Í≤ΩÏö∞)\n",
    "    if not os.path.exists(INPUT_FOLDER):\n",
    "        os.makedirs(INPUT_FOLDER)\n",
    "        with open(f\"{INPUT_FOLDER}/Motor_Log_2024.csv\", \"w\") as f:\n",
    "            f.write(\"time,currR,currS,currT,Unknown_X\\n10:00,10,10,10,0.1\")\n",
    "            \n",
    "    build_metadata_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95675008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc058ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdb8910e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Filename        Interpreted_As               Mapped_Class  \\\n",
      "0     Inj_Machine_Log_01.csv    Inj Machine Log 01               Unclassified   \n",
      "1   Plastic_Molding_Data.csv  Plastic Molding Data  Injection_Molding_Machine   \n",
      "2       Robot_Arm_Axis_X.csv      Robot Arm Axis X              Welding_Robot   \n",
      "3      Auto_Welder_Final.csv     Auto Welder Final              Welding_Robot   \n",
      "4       Factory_Pump_Vib.csv      Factory Pump Vib            Industrial_Pump   \n",
      "5            M01_Unknown.csv           M01 Unknown               Unclassified   \n",
      "6       CNC_Machine_Data.csv      CNC Machine Data                CNC_Machine   \n",
      "7                    cnc.csv                   cnc                CNC_Machine   \n",
      "8               cnc_data.csv              cnc data                CNC_Machine   \n",
      "9            cnc_data_01.csv           cnc data 01                CNC_Machine   \n",
      "10           cnc_data_02.csv           cnc data 02                CNC_Machine   \n",
      "11           cnc_data_03.csv           cnc data 03                CNC_Machine   \n",
      "12           cnc_data_04.csv           cnc data 04                CNC_Machine   \n",
      "\n",
      "    Confidence  \n",
      "0        0.337  \n",
      "1        0.437  \n",
      "2        0.406  \n",
      "3        0.557  \n",
      "4        0.622  \n",
      "5        0.233  \n",
      "6        0.806  \n",
      "7        0.756  \n",
      "8        0.713  \n",
      "9        0.663  \n",
      "10       0.655  \n",
      "11       0.649  \n",
      "12       0.713  \n"
     ]
    }
   ],
   "source": [
    "# Ïã§Ìñâ\n",
    "df_result = map_filenames_to_classes(filenames, ontology_classes)\n",
    "print(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e30b634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Interpreted_As</th>\n",
       "      <th>Mapped_Class</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inj_Machine_Log_01.csv</td>\n",
       "      <td>Inj Machine Log 01</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>0.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plastic_Molding_Data.csv</td>\n",
       "      <td>Plastic Molding Data</td>\n",
       "      <td>Injection_Molding_Machine</td>\n",
       "      <td>0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robot_Arm_Axis_X.csv</td>\n",
       "      <td>Robot Arm Axis X</td>\n",
       "      <td>Welding_Robot</td>\n",
       "      <td>0.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Auto_Welder_Final.csv</td>\n",
       "      <td>Auto Welder Final</td>\n",
       "      <td>Welding_Robot</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Factory_Pump_Vib.csv</td>\n",
       "      <td>Factory Pump Vib</td>\n",
       "      <td>Industrial_Pump</td>\n",
       "      <td>0.622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M01_Unknown.csv</td>\n",
       "      <td>M01 Unknown</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>0.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CNC_Machine_Data.csv</td>\n",
       "      <td>CNC Machine Data</td>\n",
       "      <td>CNC_Machine</td>\n",
       "      <td>0.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cnc.csv</td>\n",
       "      <td>cnc</td>\n",
       "      <td>CNC_Machine</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cnc_data.csv</td>\n",
       "      <td>cnc data</td>\n",
       "      <td>CNC_Machine</td>\n",
       "      <td>0.713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cnc_data_01.csv</td>\n",
       "      <td>cnc data 01</td>\n",
       "      <td>CNC_Machine</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cnc_data_02.csv</td>\n",
       "      <td>cnc data 02</td>\n",
       "      <td>CNC_Machine</td>\n",
       "      <td>0.655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cnc_data_03.csv</td>\n",
       "      <td>cnc data 03</td>\n",
       "      <td>CNC_Machine</td>\n",
       "      <td>0.649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cnc_data_04.csv</td>\n",
       "      <td>cnc data 04</td>\n",
       "      <td>CNC_Machine</td>\n",
       "      <td>0.713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Filename        Interpreted_As               Mapped_Class  \\\n",
       "0     Inj_Machine_Log_01.csv    Inj Machine Log 01               Unclassified   \n",
       "1   Plastic_Molding_Data.csv  Plastic Molding Data  Injection_Molding_Machine   \n",
       "2       Robot_Arm_Axis_X.csv      Robot Arm Axis X              Welding_Robot   \n",
       "3      Auto_Welder_Final.csv     Auto Welder Final              Welding_Robot   \n",
       "4       Factory_Pump_Vib.csv      Factory Pump Vib            Industrial_Pump   \n",
       "5            M01_Unknown.csv           M01 Unknown               Unclassified   \n",
       "6       CNC_Machine_Data.csv      CNC Machine Data                CNC_Machine   \n",
       "7                    cnc.csv                   cnc                CNC_Machine   \n",
       "8               cnc_data.csv              cnc data                CNC_Machine   \n",
       "9            cnc_data_01.csv           cnc data 01                CNC_Machine   \n",
       "10           cnc_data_02.csv           cnc data 02                CNC_Machine   \n",
       "11           cnc_data_03.csv           cnc data 03                CNC_Machine   \n",
       "12           cnc_data_04.csv           cnc data 04                CNC_Machine   \n",
       "\n",
       "    Confidence  \n",
       "0        0.337  \n",
       "1        0.437  \n",
       "2        0.406  \n",
       "3        0.557  \n",
       "4        0.622  \n",
       "5        0.233  \n",
       "6        0.806  \n",
       "7        0.756  \n",
       "8        0.713  \n",
       "9        0.663  \n",
       "10       0.655  \n",
       "11       0.649  \n",
       "12       0.713  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98167971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, RDF, Namespace, Literal\n",
    "\n",
    "g = Graph()\n",
    "FACT = Namespace(\"http://factory.org/\")\n",
    "\n",
    "for index, row in df_result.iterrows():\n",
    "    if row['Mapped_Class'] == \"Unclassified\":\n",
    "        continue\n",
    "        \n",
    "    # 1. Îç∞Ïù¥ÌÑ∞ÏÖã Í∞ùÏ≤¥ ÏÉùÏÑ± (ÌååÏùºÎ™Ö Í∏∞Î∞ò)\n",
    "    dataset_uri = FACT[row['Filename'].replace('.csv', '')]\n",
    "    \n",
    "    # 2. Îß§ÌïëÎêú ÌÅ¥ÎûòÏä§ Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "    # Ïòà: Injection_Molding_Machine ÌÅ¥ÎûòÏä§\n",
    "    class_uri = FACT[row['Mapped_Class']]\n",
    "    \n",
    "    # 3. [ÌïµÏã¨] Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ Ìï¥Îãπ ÌÅ¥ÎûòÏä§Ïùò Îç∞Ïù¥ÌÑ∞ÎùºÍ≥† Ï†ïÏùò\n",
    "    # ÏùòÎØ∏: \"Inj_Machine_Log_01.csvÎäî ÏÇ¨Ï∂úÍ∏∞ Îç∞Ïù¥ÌÑ∞Ïùò ÏùºÏ¢ÖÏù¥Îã§\"\n",
    "    g.add((dataset_uri, FACT.isDataOf, class_uri))\n",
    "    \n",
    "    # Ï∂îÍ∞Ä: Ïã†Î¢∞ÎèÑ Ï†êÏàòÎèÑ Î©îÌÉÄÎç∞Ïù¥ÌÑ∞Î°ú Ï†ÄÏû• (ÎÇòÏ§ëÏóê Í≤ÄÏ¶ùÏö©)\n",
    "    g.add((dataset_uri, FACT.mappingConfidence, Literal(row['Confidence'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29df9634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nd1fe5ecce7be4316b3e2b38348211c4e (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.serialize(destination='factory_data.ttl', format='turtle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808ed1b1",
   "metadata": {},
   "source": [
    "- mapped_machine -> mapped_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93877795",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ebd5658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rdflib import Graph, Literal, RDF, Namespace, XSD\n",
    "import urllib.parse\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# ============================================\n",
    "# 1. Í∑úÏπô Í∏∞Î∞ò Îß§Ìïë (Rule-based Mapping)\n",
    "# ============================================\n",
    "def build_hybrid_ontology(\n",
    "    input_folder: str,\n",
    "    ontology_classes: List[str],\n",
    "    output_file: str = \"metadata_ontology.ttl\",\n",
    "    model_name: str = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "):\n",
    "    \"\"\"\n",
    "    ÌïòÏù¥Î∏åÎ¶¨Îìú Ï†ëÍ∑ºÎ≤ïÏúºÎ°ú Ïò®ÌÜ®Î°úÏßÄ Íµ¨Ï∂ï\n",
    "    \n",
    "    Args:\n",
    "        input_folder: CSV ÌååÏùºÏù¥ ÏûàÎäî Ìè¥Îçî\n",
    "        ontology_classes: ÌëúÏ§Ä Ïò®ÌÜ®Î°úÏßÄ ÌÅ¥ÎûòÏä§ Î¶¨Ïä§Ìä∏\n",
    "        output_file: Ï∂úÎ†• TTL ÌååÏùºÎ™Ö\n",
    "        model_name: SentenceTransformer Î™®Îç∏Î™Ö\n",
    "    \"\"\"\n",
    "    print(\"üßê ÌïòÏù¥Î∏åÎ¶¨Îìú Ïò®ÌÜ®Î°úÏßÄ Íµ¨Ï∂ïÏùÑ ÏãúÏûëÌï©ÎãàÎã§...\")\n",
    "    \n",
    "    # ÎÑ§ÏûÑÏä§ÌéòÏù¥Ïä§ ÏÑ§Ï†ï\n",
    "    BASE_URI = \"http://factory.org/meta/\"\n",
    "    META = Namespace(BASE_URI)\n",
    "    FACT = Namespace(\"http://factory.org/\")\n",
    "    g = Graph()\n",
    "    g.bind(\"meta\", META)\n",
    "    g.bind(\"fact\", FACT)\n",
    "    \n",
    "    # ÌïòÏù¥Î∏åÎ¶¨Îìú Îß§Ìçº Ï¥àÍ∏∞Ìôî\n",
    "    mapper = HybridMapper(ontology_classes, model_name)\n",
    "    \n",
    "    # Ìè¥Îçî ÎÇ¥ ÌååÏùº ÌÉêÏÉâ\n",
    "    if not os.path.exists(input_folder):\n",
    "        os.makedirs(input_folder)\n",
    "        print(f\"   [ÏïàÎÇ¥] '{input_folder}' Ìè¥ÎçîÍ∞Ä ÏÉùÏÑ±ÎêòÏóàÏäµÎãàÎã§.\")\n",
    "        # Îπà DataFrameÍ≥º Graph Î∞òÌôò\n",
    "        return pd.DataFrame(), g\n",
    "    \n",
    "    files = [f for f in os.listdir(input_folder) if f.endswith((\".csv\", \".CSV\"))]\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"   [Í≤ΩÍ≥†] '{input_folder}' Ìè¥ÎçîÏóê CSV ÌååÏùºÏù¥ ÏóÜÏäµÎãàÎã§.\")\n",
    "        # Îπà DataFrameÍ≥º Graph Î∞òÌôò\n",
    "        return pd.DataFrame(), g\n",
    "    \n",
    "    # ÌååÏùºÎ≥Ñ Ïª¨Îüº Ï†ïÎ≥¥ ÏàòÏßë (Ïä§ÌÇ§ÎßàÎßå Ïä§Ï∫î)\n",
    "    file_columns = {}\n",
    "    for filename in files:\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "        try:\n",
    "            lf = pl.scan_csv(file_path)\n",
    "            schema = lf.collect_schema()\n",
    "            file_columns[filename] = list(schema.keys())\n",
    "        except Exception as e:\n",
    "            print(f\"   [Ï£ºÏùò] ÌååÏùºÏùÑ ÏùΩÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {filename} ({e})\")\n",
    "            file_columns[filename] = []\n",
    "    \n",
    "    # ÌïòÏù¥Î∏åÎ¶¨Îìú Îß§Ìïë ÏàòÌñâ\n",
    "    mapping_df = mapper.map_files(files, file_columns)\n",
    "    \n",
    "    print(\"\\nüìä Îß§Ìïë Í≤∞Í≥º:\")\n",
    "    print(mapping_df.to_string(index=False))\n",
    "    \n",
    "    # Ïò®ÌÜ®Î°úÏßÄ Íµ¨Ï∂ï\n",
    "    for _, row in mapping_df.iterrows():\n",
    "        filename = row['Filename']\n",
    "        mapped_class = row['Mapped_Class']\n",
    "        confidence = row['Confidence']\n",
    "        method = row['Method']\n",
    "        \n",
    "        if mapped_class == \"Unclassified\":\n",
    "            print(f\"   ‚ö†Ô∏è  {filename}: Îß§Ìïë Ïã§Ìå® (ÏàòÎèô Í≤ÄÌÜ† ÌïÑÏöî)\")\n",
    "            continue\n",
    "        \n",
    "        # ÌååÏùº Í≤ΩÎ°ú\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "        dataset_name = os.path.splitext(filename)[0]\n",
    "        dataset_uri = FACT[urllib.parse.quote(dataset_name)]\n",
    "        class_uri = FACT[urllib.parse.quote(mapped_class)]\n",
    "        \n",
    "        # Îç∞Ïù¥ÌÑ∞ÏÖã Í∞ùÏ≤¥ ÏÉùÏÑ±\n",
    "        g.add((dataset_uri, RDF.type, META.Dataset))\n",
    "        g.add((dataset_uri, META.hasFileName, Literal(filename)))\n",
    "        g.add((dataset_uri, META.hasFilePath, Literal(os.path.abspath(file_path))))\n",
    "        \n",
    "        # ÌÅ¥ÎûòÏä§ Îß§Ìïë\n",
    "        g.add((dataset_uri, FACT.isDataOf, class_uri))\n",
    "        g.add((dataset_uri, META.mappingConfidence, Literal(float(confidence), datatype=XSD.float)))\n",
    "        g.add((dataset_uri, META.mappingMethod, Literal(method)))\n",
    "        \n",
    "        # Ïª¨Îüº Ï†ïÎ≥¥ Ï∂îÍ∞Ä\n",
    "        if filename in file_columns:\n",
    "            for col_name in file_columns[filename]:\n",
    "                col_id = f\"{dataset_name}_{col_name}\"\n",
    "                col_uri = META[urllib.parse.quote(col_id)]\n",
    "                \n",
    "                g.add((col_uri, RDF.type, META.DataColumn))\n",
    "                g.add((dataset_uri, META.hasColumn, col_uri))\n",
    "                g.add((col_uri, META.columnName, Literal(col_name)))\n",
    "        \n",
    "        print(f\"   ‚úÖ {filename} ‚Üí {mapped_class} ({method}, confidence: {confidence:.2f})\")\n",
    "    \n",
    "    # Í≤∞Í≥º Ï†ÄÏû•\n",
    "    if len(mapping_df) > 0:  # ÌååÏùºÏù¥ ÏûàÏùÑ ÎïåÎßå Ï†ÄÏû•\n",
    "        g.serialize(destination=output_file, format=\"turtle\")\n",
    "        print(f\"\\n‚úÖ Ïò®ÌÜ®Î°úÏßÄ Íµ¨Ï∂ï ÏôÑÎ£å! ({output_file})\")\n",
    "        \n",
    "        # ÌÜµÍ≥Ñ Ï∂úÎ†•\n",
    "        method_counts = mapping_df['Method'].value_counts()\n",
    "        print(\"\\nüìà Îß§Ìïë Î∞©Î≤ï ÌÜµÍ≥Ñ:\")\n",
    "        for method, count in method_counts.items():\n",
    "            print(f\"   {method}: {count}Í∞ú\")\n",
    "    \n",
    "    return mapping_df, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e446c056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßê ÌïòÏù¥Î∏åÎ¶¨Îìú Ïò®ÌÜ®Î°úÏßÄ Íµ¨Ï∂ïÏùÑ ÏãúÏûëÌï©ÎãàÎã§...\n",
      "\n",
      "üìä Îß§Ìïë Í≤∞Í≥º:\n",
      "   Filename Interpreted_As Mapped_Class  Confidence           Method                              Column_Hint\n",
      "deoksan.csv        deoksan        Motor         0.8 column_inference Detected from columns: time, curr, currR\n",
      "   ‚úÖ deoksan.csv ‚Üí Motor (column_inference, confidence: 0.80)\n",
      "\n",
      "‚úÖ Ïò®ÌÜ®Î°úÏßÄ Íµ¨Ï∂ï ÏôÑÎ£å! (metadata_ontology_hybrid.ttl)\n",
      "\n",
      "üìà Îß§Ìïë Î∞©Î≤ï ÌÜµÍ≥Ñ:\n",
      "   column_inference: 1Í∞ú\n",
      "\n",
      "==================================================\n",
      "Îß§Ìïë Í≤∞Í≥º ÏÉÅÏÑ∏:\n",
      "==================================================\n",
      "      Filename Interpreted_As Mapped_Class  Confidence            Method  \\\n",
      "0  deoksan.csv        deoksan        Motor         0.8  column_inference   \n",
      "\n",
      "                                Column_Hint  \n",
      "0  Detected from columns: time, curr, currR  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Ïò®ÌÜ®Î°úÏßÄ ÌÅ¥ÎûòÏä§ Ï†ïÏùò\n",
    "    ontology_classes = [\n",
    "        \"Injection_Molding_Machine\",\n",
    "        \"Welding_Robot\",\n",
    "        \"Industrial_Pump\",\n",
    "        \"CNC_Machine\",\n",
    "        \"Conveyor_Belt\",\n",
    "        \"Motor\"\n",
    "    ]\n",
    "    \n",
    "    # Ïò®ÌÜ®Î°úÏßÄ Íµ¨Ï∂ï Ïã§Ìñâ\n",
    "    mapping_df, graph = build_hybrid_ontology(\n",
    "        input_folder=\"./csv_data\",\n",
    "        ontology_classes=ontology_classes,\n",
    "        output_file=\"metadata_ontology_hybrid.ttl\"\n",
    "    )\n",
    "    \n",
    "    # Í≤∞Í≥º ÌôïÏù∏\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Îß§Ìïë Í≤∞Í≥º ÏÉÅÏÑ∏:\")\n",
    "    print(\"=\"*50)\n",
    "    print(mapping_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7ebfc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
